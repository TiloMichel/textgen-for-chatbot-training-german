# Answer-aware question generation metrics
This folder contains all results from metrics for answer-aware question generation. The results were calculated with the Jupyter Notebooks `3_evaluation/multiple_model_evaluation.ipynb`.

## Results
One model was trained for answer-aware question generation and it had the following results:

| BLEU | ROUGE-L | METEOR | BERTScore |
|---|---|---|---|
| 8.93 | 0.2657 | 0.1491 | 0.4698 |